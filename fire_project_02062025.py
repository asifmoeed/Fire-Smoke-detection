# -*- coding: utf-8 -*-
"""Fire Project 10052025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aUZY2IZkBGk6YbuhLNKpEVUpO67WxJS7
"""

import cv2
import numpy as np
import threading
import time
from twilio.rest import Client
import firebase_admin
from firebase_admin import credentials, messaging
from ultralytics import YOLO
import requests

from ultralytics import YOLO

# Load YOLOv8 model (official Ultralytics implementation)
model = YOLO("yolov8n.pt")  # Nano version (fastest)

CLASS_MAP = {
    0: "person",
    # These are common class IDs for fire-related objects in custom-trained models
    # You'll need to train your own model or use these placeholder IDs
    25: "fire",
    26: "smoke",
    27: "flames"
}

!pip install streamlit

import cv2
import streamlit as st
from ultralytics import YOLO
import numpy as np
from PIL import Image
import tempfile

# --- Streamlit UI setup ---
st.set_page_config(page_title="Fire & Smoke Detection", page_icon="ðŸ”¥", layout="wide")
st.title("ðŸ”¥ Fire & Smoke Detection System")

# Sidebar settings
input_source = st.sidebar.radio("Select Input Source:", ("Webcam", "Mobile/IP Camera", "Upload Image", "Upload Video"))
conf_threshold = st.sidebar.slider("Detection Confidence Threshold", 0.1, 1.0, 0.5, 0.01)

# Load YOLO model
@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")  # Replace with "best.pt" if using your own trained model

model = load_model()

# Placeholder for messages and video
video_placeholder = st.empty()
status_text = st.empty()

def detect_and_display(frame, conf=0.5):
    results = model(frame, conf=conf)
    annotated = results[0].plot()
    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
    fire_detected = any(int(box.cls) in [25, 26, 27] for box in results[0].boxes)
    return annotated_rgb, fire_detected

# Handle input options
if input_source == "Webcam":
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        st.error("Webcam not accessible")
    else:
        st.info("Press 'Stop' to end the webcam feed")
        stop_button = st.button("Stop")
        while not stop_button:
            ret, frame = cap.read()
            if not ret:
                status_text.warning("Failed to read webcam feed")
                break
            annotated_frame, fire_detected = detect_and_display(frame, conf=conf_threshold)
            video_placeholder.image(annotated_frame, channels="RGB", use_column_width=True)
            if fire_detected:
                status_text.error("ðŸš¨ FIRE DETECTED!")
            else:
                status_text.success("âœ… No fire detected")
            stop_button = st.button("Stop")
        cap.release()

elif input_source == "Mobile/IP Camera":
    ip_url = st.sidebar.text_input("Enter Mobile/IP Camera URL (e.g., http://192.168.X.X:8080/video)")
    if ip_url:
        cap = cv2.VideoCapture(ip_url)
        if not cap.isOpened():
            st.error("Unable to access IP Camera")
        else:
            st.info("Press 'Stop' to end the IP camera feed")
            stop_button = st.button("Stop")
            while not stop_button:
                ret, frame = cap.read()
                if not ret:
                    status_text.warning("Failed to read IP camera feed")
                    break
                annotated_frame, fire_detected = detect_and_display(frame, conf=conf_threshold)
                video_placeholder.image(annotated_frame, channels="RGB", use_column_width=True)
                if fire_detected:
                    status_text.error("ðŸš¨ FIRE DETECTED!")
                else:
                    status_text.success("âœ… No fire detected")
                stop_button = st.button("Stop")
            cap.release()
    else:
        st.warning("Please enter a valid IP Camera URL")

elif input_source == "Upload Image":
    uploaded_img = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])
    if uploaded_img is not None:
        img = Image.open(uploaded_img)
        frame = np.array(img)
        annotated_frame, fire_detected = detect_and_display(frame, conf=conf_threshold)
        st.image(annotated_frame, channels="RGB", use_column_width=True)
        if fire_detected:
            st.error("ðŸš¨ FIRE DETECTED!")
        else:
            st.success("âœ… No fire detected")

elif input_source == "Upload Video":
    uploaded_vid = st.file_uploader("Upload a video", type=["mp4", "mov", "avi"])
    if uploaded_vid is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_vid.read())
        cap = cv2.VideoCapture(tfile.name)
        st.info("Processing video...")

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            annotated_frame, fire_detected = detect_and_display(frame, conf=conf_threshold)
            video_placeholder.image(annotated_frame, channels="RGB", use_column_width=True)
            if fire_detected:
                status_text.error("ðŸš¨ FIRE DETECTED!")
            else:
                status_text.success("âœ… No fire detected")
        cap.release()


